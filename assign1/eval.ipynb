{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle, spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/small_data_sampled.csv')\n",
    "\n",
    "#rename text_filtered to text\n",
    "data.rename(columns = {'text_filtered':'text'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and eval model with input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model, X_train, Y_train, X_test, Y_test):\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results = {}\n",
    "    results['accuracy'] = accuracy_score(Y_test, y_pred)\n",
    "    results['precision'] = precision_score(Y_test, y_pred, average='weighted')\n",
    "    results['recall'] = recall_score(Y_test, y_pred, average='weighted')\n",
    "    results['f1'] = f1_score(Y_test, y_pred, average='weighted')\n",
    "    results['confusion_matrix'] = confusion_matrix(Y_test, y_pred)\n",
    "    results['model'] = model\n",
    "    results['y_pred'] = y_pred\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(matrix):\n",
    "    # Display the confusion matrix as an image\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(matrix, annot=True, fmt='d', ax=ax)\n",
    "    \n",
    "    # Set the labels\n",
    "    ax.set_xlabel('Predicted', fontsize=20)\n",
    "    ax.set_ylabel('Actual', fontsize=20)\n",
    "    ax.set_title('Confusion Matrix', fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countVectorizerAux(data, ngram_range_max):\n",
    "    vectorizer = CountVectorizer(analyzer='word', lowercase=False, stop_words='english', ngram_range=(1, ngram_range_max))\n",
    "    X = vectorizer.fit_transform(data['text']).toarray()\n",
    "    y = data['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "    results = {}\n",
    "    results['X_train'] = X_train\n",
    "    results['X_test'] = X_test\n",
    "    results['y_train'] = y_train\n",
    "    results['y_test'] = y_test\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfVectorizerAux(data, ngram_range_max):\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', lowercase=True, stop_words='english', ngram_range=(1, ngram_range_max))\n",
    "    X = vectorizer.fit_transform(data['text']).toarray()\n",
    "    y = data['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "    results = {}\n",
    "    results['X_train'] = X_train\n",
    "    results['X_test'] = X_test\n",
    "    results['y_train'] = y_train\n",
    "    results['y_test'] = y_test\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from preprocessing.ipynb exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load small_data_sample.csv\n",
    "small_data_sample = pd.read_csv('datasets/small_data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickled data\n",
    "with open('datasets/pickle/train_features.pkl', 'rb') as f:\n",
    "    train_features = pickle.load(f)\n",
    "\n",
    "with open('datasets/pickle/train_features_embeddes.pkl', 'rb') as f:\n",
    "    train_features_embeddes = pickle.load(f)\n",
    "\n",
    "with open('datasets/pickle/train_features_text_and_tokens.pkl', 'rb') as f:\n",
    "    train_features_text_and_tokens = pickle.load(f)\n",
    "\n",
    "with open('datasets/pickle/train_features_entities.pkl', 'rb') as f:\n",
    "    train_features_entities = pickle.load(f)\n",
    "\n",
    "with open('datasets/pickle/train_features_no_er.pkl', 'rb') as f:\n",
    "    train_features_no_er = pickle.load(f)\n",
    "\n",
    "with open('datasets/pickle/train_labels.pkl', 'rb') as f:\n",
    "    train_labels = pickle.load(f)\n",
    "    \n",
    "with open('datasets/pickle/test_features.pkl', 'rb') as f:\n",
    "    test_features = pickle.load(f)\n",
    "    \n",
    "with open('datasets/pickle/test_features_embeddes.pkl', 'rb') as f:\n",
    "    test_features_embeddes = pickle.load(f)\n",
    "    \n",
    "with open('datasets/pickle/test_features_text_and_tokens.pkl', 'rb') as f:\n",
    "    test_features_text_and_tokens = pickle.load(f)\n",
    "    \n",
    "with open('datasets/pickle/test_features_entities.pkl', 'rb') as f:\n",
    "    test_features_entities = pickle.load(f)\n",
    "    \n",
    "with open('datasets/pickle/test_features_no_er.pkl', 'rb') as f:\n",
    "    test_features_no_er = pickle.load(f)\n",
    "    \n",
    "with open('datasets/pickle/test_labels.pkl', 'rb') as f:\n",
    "    test_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differences(model, train_features, test_features):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', DictVectorizer()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(train_features, train_labels)\n",
    "\n",
    "    # Predict the test data\n",
    "    preds = pipeline.predict(test_features)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(test_labels, preds)\n",
    "    f1 = f1_score(test_labels, preds, average='weighted')\n",
    "    precision = precision_score(test_labels, preds, average='weighted')\n",
    "    recall = recall_score(test_labels, preds, average='weighted')\n",
    "\n",
    "    # Create a DataFrame to store results\n",
    "    df_results = pd.DataFrame({\n",
    "        'features': test_features,\n",
    "        'actual_labels': test_labels,\n",
    "        'predicted_labels': preds,\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "\n",
    "    # Filter out instances where prediction differs from the actual label\n",
    "    different_predictions = df_results[df_results['actual_labels'] != df_results['predicted_labels']]\n",
    "\n",
    "    return different_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = differences(LogisticRegression(c=0.1, penalty='l2', solver='liblinear'), train_features, test_features)\n",
    "results.to_csv('/datasets/exploration/lr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Embeddigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = differences(SVC(c=1.0, kernel='rbf'), train_features, test_features)\n",
    "results.to_csv('/datasets/exploration/svc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizerResults = countVectorizerAux(data, 1)\n",
    "countVectorizerResults2 = countVectorizerAux(data, 2)\n",
    "countVectorizerResults3 = countVectorizerAux(data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    MultinomialNB(), \n",
    "    countVectorizerResults['X_train'], \n",
    "    countVectorizerResults['y_train'], \n",
    "    countVectorizerResults['X_test'], \n",
    "    countVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    MultinomialNB(), \n",
    "    countVectorizerResults2['X_train'], \n",
    "    countVectorizerResults2['y_train'], \n",
    "    countVectorizerResults2['X_test'], \n",
    "    countVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    MultinomialNB(), \n",
    "    countVectorizerResults3['X_train'], \n",
    "    countVectorizerResults3['y_train'], \n",
    "    countVectorizerResults3['X_test'], \n",
    "    countVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    DecisionTreeClassifier(max_depth=None, min_samples_split=5), \n",
    "    countVectorizerResults['X_train'], \n",
    "    countVectorizerResults['y_train'], \n",
    "    countVectorizerResults['X_test'], \n",
    "    countVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    DecisionTreeClassifier(max_depth=None, min_samples_split=5), \n",
    "    countVectorizerResults2['X_train'], \n",
    "    countVectorizerResults2['y_train'], \n",
    "    countVectorizerResults2['X_test'], \n",
    "    countVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    DecisionTreeClassifier(max_depth=None, min_samples_split=5), \n",
    "    countVectorizerResults3['X_train'], \n",
    "    countVectorizerResults3['y_train'], \n",
    "    countVectorizerResults3['X_test'], \n",
    "    countVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    LogisticRegression(penalty='l2', solver='liblinear'), \n",
    "    countVectorizerResults['X_train'], \n",
    "    countVectorizerResults['y_train'], \n",
    "    countVectorizerResults['X_test'], \n",
    "    countVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    LogisticRegression(penalty='l2', solver='liblinear'), \n",
    "    countVectorizerResults2['X_train'], \n",
    "    countVectorizerResults2['y_train'], \n",
    "    countVectorizerResults2['X_test'], \n",
    "    countVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    LogisticRegression(penalty='l2', solver='liblinear'), \n",
    "    countVectorizerResults3['X_train'], \n",
    "    countVectorizerResults3['y_train'], \n",
    "    countVectorizerResults3['X_test'], \n",
    "    countVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    RandomForestClassifier(max_depth=None, min_samples_split=10), \n",
    "    countVectorizerResults['X_train'], \n",
    "    countVectorizerResults['y_train'], \n",
    "    countVectorizerResults['X_test'], \n",
    "    countVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    RandomForestClassifier(max_depth=None, min_samples_split=10), \n",
    "    countVectorizerResults2['X_train'], \n",
    "    countVectorizerResults2['y_train'], \n",
    "    countVectorizerResults2['X_test'], \n",
    "    countVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    RandomForestClassifier(max_depth=None, min_samples_split=10), \n",
    "    countVectorizerResults3['X_train'], \n",
    "    countVectorizerResults3['y_train'], \n",
    "    countVectorizerResults3['X_test'], \n",
    "    countVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    SVC(c=10, kernel= 'rbf'), \n",
    "    countVectorizerResults['X_train'], \n",
    "    countVectorizerResults['y_train'], \n",
    "    countVectorizerResults['X_test'], \n",
    "    countVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    SVC(c=10, kernel= 'rbf'), \n",
    "    countVectorizerResults2['X_train'], \n",
    "    countVectorizerResults2['y_train'], \n",
    "    countVectorizerResults2['X_test'], \n",
    "    countVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    SVC(c=10, kernel= 'rbf'), \n",
    "    countVectorizerResults3['X_train'], \n",
    "    countVectorizerResults3['y_train'], \n",
    "    countVectorizerResults3['X_test'], \n",
    "    countVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVectorizerResults = countVectorizerAux(data, 1)\n",
    "tfidfVectorizerResults2 = countVectorizerAux(data, 2)\n",
    "tfidfVectorizerResults3 = countVectorizerAux(data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    MultinomialNB(), \n",
    "    tfidfVectorizerResults['X_train'], \n",
    "    tfidfVectorizerResults['y_train'], \n",
    "    tfidfVectorizerResults['X_test'], \n",
    "    tfidfVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    MultinomialNB(), \n",
    "    tfidfVectorizerResults2['X_train'], \n",
    "    tfidfVectorizerResults2['y_train'], \n",
    "    tfidfVectorizerResults2['X_test'], \n",
    "    tfidfVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    MultinomialNB(), \n",
    "    tfidfVectorizerResults3['X_train'], \n",
    "    tfidfVectorizerResults3['y_train'], \n",
    "    tfidfVectorizerResults3['X_test'], \n",
    "    tfidfVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    DecisionTreeClassifier(max_depth=None, min_samples_split=5), \n",
    "    tfidfVectorizerResults['X_train'], \n",
    "    tfidfVectorizerResults['y_train'], \n",
    "    tfidfVectorizerResults['X_test'], \n",
    "    tfidfVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    DecisionTreeClassifier(max_depth=None, min_samples_split=5), \n",
    "    tfidfVectorizerResults2['X_train'], \n",
    "    tfidfVectorizerResults2['y_train'], \n",
    "    tfidfVectorizerResults2['X_test'], \n",
    "    tfidfVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    DecisionTreeClassifier(max_depth=None, min_samples_split=5), \n",
    "    tfidfVectorizerResults3['X_train'], \n",
    "    tfidfVectorizerResults3['y_train'], \n",
    "    tfidfVectorizerResults3['X_test'], \n",
    "    tfidfVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    LogisticRegression(penalty='l2', solver='liblinear'), \n",
    "    tfidfVectorizerResults['X_train'], \n",
    "    tfidfVectorizerResults['y_train'], \n",
    "    tfidfVectorizerResults['X_test'], \n",
    "    tfidfVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    LogisticRegression(penalty='l2', solver='liblinear'), \n",
    "    tfidfVectorizerResults2['X_train'], \n",
    "    tfidfVectorizerResults2['y_train'], \n",
    "    tfidfVectorizerResults2['X_test'], \n",
    "    tfidfVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    LogisticRegression(penalty='l2', solver='liblinear'), \n",
    "    tfidfVectorizerResults3['X_train'], \n",
    "    tfidfVectorizerResults3['y_train'], \n",
    "    tfidfVectorizerResults3['X_test'], \n",
    "    tfidfVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    RandomForestClassifier(max_depth=None, min_samples_split=10), \n",
    "    tfidfVectorizerResults['X_train'], \n",
    "    tfidfVectorizerResults['y_train'], \n",
    "    tfidfVectorizerResults['X_test'], \n",
    "    tfidfVectorizerResults['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    RandomForestClassifier(max_depth=None, min_samples_split=10), \n",
    "    tfidfVectorizerResults2['X_train'], \n",
    "    tfidfVectorizerResults2['y_train'], \n",
    "    tfidfVectorizerResults2['X_test'], \n",
    "    tfidfVectorizerResults2['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb_simple = train_test_model(\n",
    "    RandomForestClassifier(max_depth=None, min_samples_split=10), \n",
    "    tfidfVectorizerResults3['X_train'], \n",
    "    tfidfVectorizerResults3['y_train'], \n",
    "    tfidfVectorizerResults3['X_test'], \n",
    "    tfidfVectorizerResults3['y_test'],\n",
    "    )\n",
    "print(results_nb_simple['accuracy'], results_nb_simple['precision'], results_nb_simple['recall'], results_nb_simple['f1'])\n",
    "print(results_nb_simple['confusion_matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
